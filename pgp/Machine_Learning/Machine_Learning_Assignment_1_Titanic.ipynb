{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TEST\n",
    "Q1- Titanic Data set:\n",
    "Find survival count\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Index', 'PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Pclass_1',\n",
      "       'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def solution():\n",
    "    #reading from the file Titanic_train.csv\n",
    "    train=pd.read_csv('res/Titanic_train.csv')\n",
    "    #view the dataset\n",
    "    #print(train.head())\n",
    "\n",
    "    train.rename(columns = {'Unnamed: 0':'Index'},inplace=True)  ## Renaming index column\n",
    "    #print(train.columns)\n",
    "    #print(train.shape)\n",
    "    #print(train.dtypes)\n",
    "    #print(train.isnull().sum())\n",
    "    #print(train.describe())\n",
    "    train = pd.get_dummies(train, columns=['Sex','Pclass','Embarked'] )\n",
    "    #print(train.head())\n",
    "    print(train.columns)\n",
    "    #train = train.join(dum_df)\n",
    "    #print(train)\n",
    "    \n",
    "    '''Write your code here....\n",
    "    .......\n",
    "    .......\n",
    "    '''\n",
    "    \n",
    "    sur_pclass3 = train['PassengerId'][(train[\"Survived\"] == 1) & (train[\"Pclass_3\"] == 1)].count()\n",
    "    sur_male = train['PassengerId'][(train[\"Survived\"] == 0) & (train[\"Sex_male\"] == 1)].count()\n",
    "    sur_south = train['PassengerId'][(train[\"Survived\"] == 1) & (train[\"Embarked_S\"] == 1)].count()\n",
    "    \n",
    "    \n",
    "    # Creating a list of the answer\n",
    "    result=[sur_pclass3,sur_male,sur_south]\n",
    "    # NOTE: Here, 100, 200 and 300 are the answer of 1st, 2nd and 3rd question respectively. Change it accordingly.\n",
    "    \n",
    "    # Finally create a dataframe of the final output  and write the output to output.csv\n",
    "    \n",
    "    result=pd.DataFrame(result)\n",
    "    # writing output to output.csv\n",
    "    result.to_csv('output/output_1_1.csv', header=False, index=False)\n",
    "    \n",
    "solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTitanic Datase - Predict the age of missing passengers\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q2 - Titanic Datase - Predict the age of missing passengers\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   781.000000  781.000000  781.000000  628.000000  781.000000   \n",
      "mean    445.335467    0.371319    2.309859   29.603376    0.503201   \n",
      "std     257.978890    0.483467    0.835904   14.427135    1.052008   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     221.000000    0.000000    2.000000   20.000000    0.000000   \n",
      "50%     443.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     671.000000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   74.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  781.000000  781.000000  \n",
      "mean     0.362356   30.312072  \n",
      "std      0.796187   43.012711  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.895800  \n",
      "50%      0.000000   14.108300  \n",
      "75%      0.000000   30.500000  \n",
      "max      6.000000  512.329200  \n",
      "           Pclass    Survived         Age  GenderLabel\n",
      "count  628.000000  628.000000  628.000000   628.000000\n",
      "mean     2.246815    0.391720   28.222930     0.648089\n",
      "std      0.834602    0.488524   11.944769     0.477947\n",
      "min      1.000000    0.000000    1.000000     0.000000\n",
      "25%      1.000000    0.000000   20.000000     0.000000\n",
      "50%      3.000000    0.000000   28.000000     1.000000\n",
      "75%      3.000000    1.000000   38.000000     1.000000\n",
      "max      3.000000    1.000000   45.000000     1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153, 63430, 26]\n"
     ]
    }
   ],
   "source": [
    "def solution():\n",
    "    result=[]\n",
    "    #reading from the file Titanic_train.csv\n",
    "    train=pd.read_csv('res/Titanic_train.csv')\n",
    "    #view the dataset\n",
    "    train.drop(columns = ['Unnamed: 0'], axis =1, inplace=True)  ## deleting unnamed column\n",
    "    #print(train.head(20))\n",
    "    print(train.describe())\n",
    "    \n",
    "    '''Write your code here....\n",
    "    .......\n",
    "    .......\n",
    "    '''\n",
    "    df = train['PassengerId'][train['Age'].isnull() == True]\n",
    "    #print(df)\n",
    "    null_cnt = df.count()\n",
    "    result.append(null_cnt)\n",
    "    #print(df.index)\n",
    "    sum_idx = 0\n",
    "    for i in df.index:\n",
    "        #print(i)\n",
    "        sum_idx += i\n",
    "    \n",
    "    result.append(sum_idx)\n",
    "    \n",
    "    #Using Label Encoder to transform Sex column in 1 and 0\n",
    "    le = LabelEncoder()\n",
    "    df = train[['Pclass','Survived','Sex','Age']].copy()\n",
    "    df['GenderLabel']=le.fit_transform(df['Sex'])\n",
    "    df.drop(columns = ['Sex'],axis =1, inplace = True)\n",
    "    #print(df.describe())\n",
    "    #print(df['Age'].values)\n",
    "    \n",
    "    df1 = df.loc[(df['Age'].isnull() == True)].copy()\n",
    "    df2 = df.loc[(df['Age'].isnull() == False)].copy()\n",
    "    \n",
    "    \n",
    "    #df2['Age'].hist(figsize=(10,10))\n",
    "    #plt.show()\n",
    "    \n",
    "    #df2.boxplot(figsize=(10,15))\n",
    "    #plt.show()\n",
    "    \n",
    "    sns.distplot(df2['Age'], hist=True, kde=True, color = 'darkblue')\n",
    "    \n",
    "    for col in ['Age']:\n",
    "        percentiles = df2[col].quantile([0.01,0.85]).values #Filtering 1%(0-1), 1%(99-100) extreme outlier data\n",
    "        df2[col] = np.clip(df2[col], percentiles[0], percentiles[1])\n",
    "    \n",
    "    #sns.distplot(df2['Age'], hist=True, kde=True, color = 'darkblue')\n",
    "    print(df2.describe())\n",
    "    \n",
    "    df2.boxplot(figsize=(10,15))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #print(df2)\n",
    "    \n",
    "    #Splitting the data in test and train\n",
    "    X_train = df2[['Pclass','Survived','GenderLabel']]\n",
    "    X_test = df1[['Pclass','Survived','GenderLabel']]\n",
    "    y_train = df2['Age']\n",
    "    y_test = df1['Age']\n",
    "    \n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_train.shape)\n",
    "    #print(y_test.shape)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "  \n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_test)\n",
    "    pred_mean = int(y_pred.mean())\n",
    "    \n",
    "    result.append(pred_mean)\n",
    "    # Creating a list of the answer\n",
    "    \n",
    "    # NOTE: Here, 100, 200 and 300 are the answer of 1st, 2nd and 3rd question respectively. Change it accordingly.\n",
    "    \n",
    "    # Finally create a dataframe of the final output  and write the output to output.csv\n",
    "    print(result)\n",
    "    result=pd.DataFrame(result)\n",
    "    # writing output to output.csv\n",
    "    result.to_csv('output/output.csv', header=False, index=False)\n",
    "    \n",
    "solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQ3 - Titanic Datase - Classification Model\\n'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q3 - Titanic Datase - Classification Model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290, 86, 80.23]\n"
     ]
    }
   ],
   "source": [
    "def solution():\n",
    "    #To store the results\n",
    "    result = []\n",
    "    \n",
    "    #reading from the file Titanic_train.csv\n",
    "    train=pd.read_csv('res/Titanic_train.csv')\n",
    "    #view the dataset\n",
    "    train.drop(columns = ['Unnamed: 0'], axis =1, inplace=True)  ## deleting unnamed column\n",
    "    #print(train.head())\n",
    "    #reading Test dataset\n",
    "    test = pd.read_csv('res/Titanic_test.csv')\n",
    "    test.drop(columns = ['Unnamed: 0'], axis =1, inplace=True)  ## deleting unnamed column\n",
    "    #print(df_Y)\n",
    "    \n",
    "    #print(test.describe())\n",
    "    \n",
    "    \n",
    "    '''Write your code here....\n",
    "    .......\n",
    "    .......\n",
    "    '''\n",
    "    df_X = train[train['Age'].isnull() == False].copy()\n",
    "    #print(df)\n",
    "    \n",
    "    df_X['AdultOrChild'] = np.where(df_X['Age'] < 18, 'Child','Adult') \n",
    "    #df['AdultOrChild'] = ['Child' if x < 18 else 'Adult' for x in df['Age']]\n",
    "    #print(df)\n",
    "    #Finding the total number of survived\n",
    "    sur_adult_train = df_X['PassengerId'][(df_X[\"Survived\"] == 1) & (df_X[\"AdultOrChild\"] == 'Adult')].count()\n",
    "    sur_child_train = df_X['PassengerId'][(df_X[\"Survived\"] == 1) & (df_X[\"AdultOrChild\"] == 'Child')].count()\n",
    "    \n",
    "    # for Test Data\n",
    "    df_Y = test[test['Age'].isnull() == False].copy()\n",
    "    #print(df)\n",
    "    \n",
    "    df_Y['AdultOrChild'] = np.where(df_Y['Age'] < 18, 'Child','Adult') \n",
    "    #df['AdultOrChild'] = ['Child' if x < 18 else 'Adult' for x in df['Age']]\n",
    "    #print(df)\n",
    "    #Finding the total number of survived\n",
    "    sur_adult_test = df_Y['PassengerId'][(df_Y[\"Survived\"] == 1) & (df_Y[\"AdultOrChild\"] == 'Adult')].count()\n",
    "    sur_child_test = df_Y['PassengerId'][(df_Y[\"Survived\"] == 1) & (df_Y[\"AdultOrChild\"] == 'Child')].count()\n",
    "    \n",
    "    Total_survived = sur_adult_train + sur_child_train + sur_adult_test + sur_child_test\n",
    "    #print(Total_survived)\n",
    "    result.append(Total_survived)\n",
    "    \n",
    "    #Classification model to predict the Survived Category\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    #For Test Data\n",
    "    df_X = df_X[['Pclass','Sex','Age','Survived']].copy()\n",
    "    df_X['GenderLabel']=le.fit_transform(df_X['Sex'])\n",
    "    df_X.drop(columns = ['Sex'],axis =1, inplace = True)\n",
    "    df_X.rename(columns = {'GenderLabel':'Sex'},inplace=True)\n",
    "    #print(df_X)\n",
    "    # For Train Data\n",
    "    df_Y = df_Y[['Pclass','Sex','Age','Survived']].copy()\n",
    "    df_Y['GenderLabel']=le.fit_transform(df_Y['Sex'])\n",
    "    df_Y.drop(columns = ['Sex'],axis =1, inplace = True)\n",
    "    df_Y.rename(columns = {'GenderLabel':'Sex'},inplace=True)\n",
    "    #print(df_Y)\n",
    "    \n",
    "    #Splitting the data in test and train\n",
    "    X_train = df_X[['Pclass','Sex','Age']]\n",
    "    y_train = df_X['Survived']\n",
    "    X_test = df_Y[['Pclass','Sex','Age']]\n",
    "    y_test = df_Y['Survived']\n",
    "    \n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_train.shape)\n",
    "    #print(y_test.shape)\n",
    "    \n",
    "    #Logistic Regression for prediction\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(X_train, y_train)\n",
    "    y_pred = logr.predict(X_test)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    #print(confusion_matrix(y_test,y_pred))\n",
    "    #print(tn, fp, fn, tp)\n",
    "    37,5,12,32\n",
    "    #Getting total of confusion matirx\n",
    "    result.append(tn + fp + fn + tp)\n",
    "    \n",
    "    #Model Performance\n",
    "    #acc = round(((tp+tn)/(tn + fp + fn + tp)) * 100,2)\n",
    "    acc = round(accuracy_score(y_test, y_pred)*100,2)\n",
    "    #print(acc,acc_2)\n",
    "    result.append(acc)\n",
    "    \n",
    "    \n",
    "    # Finally create a dataframe of the final output  and write the output to output.csv\n",
    "    print(result)\n",
    "    result=pd.DataFrame(result)\n",
    "    # writing output to output.csv\n",
    "    result.to_csv('output/output.csv', header=False, index=False)\n",
    "    \n",
    "solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
